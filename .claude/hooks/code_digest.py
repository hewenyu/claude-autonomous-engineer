#!/usr/bin/env python3
"""
Code Digest Generator
ç”Ÿæˆä»£ç åº“çš„ç»“æ„åŒ–æ‘˜è¦ï¼Œå¸®åŠ© Claude åœ¨ä¸Šä¸‹æ–‡å‹ç¼©åæ¢å¤å¯¹ä»£ç åº“çš„ç†è§£

åŠŸèƒ½ï¼š
1. æ‰«æä»£ç åº“ç»“æ„
2. æå–å‡½æ•°/ç±»ç­¾å
3. è¯†åˆ«ä¾èµ–å…³ç³»
4. ç”Ÿæˆå¯è¯»çš„æ‘˜è¦æ–‡ä»¶

ä½¿ç”¨æ–¹å¼ï¼š
  python3 code_digest.py generate [root_path]
  python3 code_digest.py update <file_path>  # æ›´æ–°å•ä¸ªæ–‡ä»¶çš„æ‘˜è¦
"""

import sys
import os
import json
import re
import hashlib
from pathlib import Path
from datetime import datetime

STATUS_DIR = ".claude/status"
DIGEST_FILE = f"{STATUS_DIR}/code_digest.json"

# å¿½ç•¥çš„ç›®å½•å’Œæ–‡ä»¶
IGNORE_DIRS = {
    '.git', '__pycache__', 'node_modules', 'venv', '.venv', 
    'env', '.env', 'dist', 'build', '.claude', 'coverage',
    '.pytest_cache', '.mypy_cache', 'eggs', '*.egg-info'
}

IGNORE_FILES = {
    '.DS_Store', 'Thumbs.db', '*.pyc', '*.pyo', '*.class',
    '*.so', '*.dll', '*.exe', 'package-lock.json', 'yarn.lock'
}

# æ”¯æŒçš„ä»£ç æ–‡ä»¶ç±»å‹
CODE_EXTENSIONS = {
    '.py': 'python',
    '.js': 'javascript',
    '.ts': 'typescript',
    '.jsx': 'javascript',
    '.tsx': 'typescript',
    '.go': 'go',
    '.rs': 'rust',
    '.java': 'java',
    '.cpp': 'cpp',
    '.c': 'c',
    '.h': 'c',
    '.hpp': 'cpp',
    '.rb': 'ruby',
    '.php': 'php',
}

def should_ignore(path):
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¿™ä¸ªè·¯å¾„"""
    name = os.path.basename(path)
    
    for pattern in IGNORE_DIRS | IGNORE_FILES:
        if '*' in pattern:
            if name.endswith(pattern.replace('*', '')):
                return True
        elif name == pattern:
            return True
    
    return False

def get_file_hash(content):
    """è·å–å†…å®¹çš„ hash"""
    return hashlib.md5(content.encode()).hexdigest()[:8]

def extract_python_signatures(content):
    """æå– Python å‡½æ•°å’Œç±»ç­¾å"""
    signatures = []
    
    # ç±»å®šä¹‰
    for match in re.finditer(r'^class\s+(\w+)(?:\(([^)]*)\))?:', content, re.MULTILINE):
        class_name = match.group(1)
        bases = match.group(2) or ''
        signatures.append({
            'type': 'class',
            'name': class_name,
            'signature': f"class {class_name}({bases})" if bases else f"class {class_name}",
            'line': content[:match.start()].count('\n') + 1
        })
    
    # å‡½æ•°å®šä¹‰
    for match in re.finditer(
        r'^(\s*)(async\s+)?def\s+(\w+)\s*\(([^)]*)\)(?:\s*->\s*([^:]+))?:',
        content, re.MULTILINE
    ):
        indent = len(match.group(1))
        is_async = bool(match.group(2))
        func_name = match.group(3)
        params = match.group(4).strip()
        return_type = match.group(5).strip() if match.group(5) else None
        
        sig = f"{'async ' if is_async else ''}def {func_name}({params})"
        if return_type:
            sig += f" -> {return_type}"
        
        signatures.append({
            'type': 'method' if indent > 0 else 'function',
            'name': func_name,
            'signature': sig,
            'line': content[:match.start()].count('\n') + 1,
            'is_async': is_async
        })
    
    return signatures

def extract_js_ts_signatures(content):
    """æå– JavaScript/TypeScript å‡½æ•°å’Œç±»ç­¾å"""
    signatures = []
    
    # ç±»å®šä¹‰
    for match in re.finditer(r'(?:export\s+)?class\s+(\w+)(?:\s+extends\s+(\w+))?', content):
        class_name = match.group(1)
        extends = match.group(2)
        sig = f"class {class_name}"
        if extends:
            sig += f" extends {extends}"
        signatures.append({
            'type': 'class',
            'name': class_name,
            'signature': sig,
            'line': content[:match.start()].count('\n') + 1
        })
    
    # å‡½æ•°å®šä¹‰
    for match in re.finditer(
        r'(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\(([^)]*)\)',
        content
    ):
        func_name = match.group(1)
        params = match.group(2).strip()
        signatures.append({
            'type': 'function',
            'name': func_name,
            'signature': f"function {func_name}({params})",
            'line': content[:match.start()].count('\n') + 1
        })
    
    # ç®­å¤´å‡½æ•°
    for match in re.finditer(
        r'(?:export\s+)?(?:const|let)\s+(\w+)\s*=\s*(?:async\s+)?\([^)]*\)\s*=>',
        content
    ):
        func_name = match.group(1)
        signatures.append({
            'type': 'arrow_function',
            'name': func_name,
            'signature': f"const {func_name} = (...) =>",
            'line': content[:match.start()].count('\n') + 1
        })
    
    return signatures

def extract_signatures(file_path, content, lang):
    """æ ¹æ®è¯­è¨€æå–ç­¾å"""
    if lang == 'python':
        return extract_python_signatures(content)
    elif lang in ('javascript', 'typescript'):
        return extract_js_ts_signatures(content)
    else:
        # å¯¹äºå…¶ä»–è¯­è¨€ï¼Œå°è¯•é€šç”¨æ¨¡å¼
        return []

def extract_imports(content, lang):
    """æå–å¯¼å…¥è¯­å¥"""
    imports = []
    
    if lang == 'python':
        for match in re.finditer(r'^(?:from\s+(\S+)\s+)?import\s+(.+)$', content, re.MULTILINE):
            from_module = match.group(1)
            imports_str = match.group(2)
            if from_module:
                imports.append(f"from {from_module} import ...")
            else:
                imports.append(f"import {imports_str.split(',')[0].strip()}")
    
    elif lang in ('javascript', 'typescript'):
        for match in re.finditer(r'^import\s+.+\s+from\s+[\'"]([^\'"]+)[\'"]', content, re.MULTILINE):
            imports.append(match.group(1))
    
    return imports[:10]  # é™åˆ¶æ•°é‡

def analyze_file(file_path):
    """åˆ†æå•ä¸ªæ–‡ä»¶"""
    ext = os.path.splitext(file_path)[1].lower()
    lang = CODE_EXTENSIONS.get(ext)
    
    if not lang:
        return None
    
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
    except:
        return None
    
    if len(content) > 100000:  # è·³è¿‡è¶…å¤§æ–‡ä»¶
        return {
            'path': file_path,
            'language': lang,
            'status': 'skipped',
            'reason': 'file too large'
        }
    
    return {
        'path': file_path,
        'language': lang,
        'hash': get_file_hash(content),
        'lines': content.count('\n') + 1,
        'signatures': extract_signatures(file_path, content, lang),
        'imports': extract_imports(content, lang),
        'last_analyzed': datetime.now().isoformat()
    }

def scan_directory(root_path='.'):
    """æ‰«æç›®å½•ç”Ÿæˆæ‘˜è¦"""
    files = []
    
    for dirpath, dirnames, filenames in os.walk(root_path):
        # è¿‡æ»¤å¿½ç•¥çš„ç›®å½•
        dirnames[:] = [d for d in dirnames if not should_ignore(d)]
        
        for filename in filenames:
            if should_ignore(filename):
                continue
            
            file_path = os.path.join(dirpath, filename)
            ext = os.path.splitext(filename)[1].lower()
            
            if ext in CODE_EXTENSIONS:
                analysis = analyze_file(file_path)
                if analysis:
                    files.append(analysis)
    
    return files

def generate_digest(root_path='.'):
    """ç”Ÿæˆå®Œæ•´çš„ä»£ç æ‘˜è¦"""
    print(f"Scanning {root_path}...")
    
    files = scan_directory(root_path)
    
    # æŒ‰ç›®å½•ç»„ç»‡
    structure = {}
    for f in files:
        path = f['path']
        parts = path.split(os.sep)
        current = structure
        for part in parts[:-1]:
            if part not in current:
                current[part] = {}
            current = current[part]
        current[parts[-1]] = {
            'lang': f['language'],
            'lines': f.get('lines', 0),
            'signatures': len(f.get('signatures', []))
        }
    
    digest = {
        'generated_at': datetime.now().isoformat(),
        'root_path': os.path.abspath(root_path),
        'stats': {
            'total_files': len(files),
            'total_lines': sum(f.get('lines', 0) for f in files),
            'by_language': {}
        },
        'files': files,
        'structure': structure
    }
    
    # ç»Ÿè®¡è¯­è¨€åˆ†å¸ƒ
    for f in files:
        lang = f['language']
        if lang not in digest['stats']['by_language']:
            digest['stats']['by_language'][lang] = {'files': 0, 'lines': 0}
        digest['stats']['by_language'][lang]['files'] += 1
        digest['stats']['by_language'][lang]['lines'] += f.get('lines', 0)
    
    # ä¿å­˜
    os.makedirs(STATUS_DIR, exist_ok=True)
    with open(DIGEST_FILE, 'w') as f:
        json.dump(digest, f, indent=2)
    
    print(f"âœ… Digest saved to {DIGEST_FILE}")
    print(f"   Files analyzed: {len(files)}")
    print(f"   Total lines: {digest['stats']['total_lines']}")
    
    return digest

def print_summary():
    """æ‰“å°æ‘˜è¦"""
    if not os.path.exists(DIGEST_FILE):
        print("No digest found. Run 'generate' first.")
        return
    
    with open(DIGEST_FILE, 'r') as f:
        digest = json.load(f)
    
    print("\nğŸ“Š Code Digest Summary")
    print("=" * 50)
    print(f"Generated: {digest['generated_at']}")
    print(f"Root: {digest['root_path']}")
    print(f"\nStats:")
    print(f"  Total files: {digest['stats']['total_files']}")
    print(f"  Total lines: {digest['stats']['total_lines']}")
    print(f"\nBy language:")
    for lang, stats in digest['stats']['by_language'].items():
        print(f"  {lang}: {stats['files']} files, {stats['lines']} lines")
    
    print("\nTop files by signatures:")
    files_with_sigs = [(f['path'], len(f.get('signatures', []))) 
                       for f in digest['files'] 
                       if f.get('signatures')]
    files_with_sigs.sort(key=lambda x: x[1], reverse=True)
    for path, count in files_with_sigs[:10]:
        print(f"  {path}: {count} signatures")

def main():
    if len(sys.argv) < 2:
        print(__doc__)
        return
    
    cmd = sys.argv[1]
    
    if cmd == 'generate':
        root = sys.argv[2] if len(sys.argv) > 2 else '.'
        generate_digest(root)
    elif cmd == 'summary':
        print_summary()
    else:
        print(__doc__)

if __name__ == "__main__":
    main()
