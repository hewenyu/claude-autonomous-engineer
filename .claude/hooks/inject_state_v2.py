#!/usr/bin/env python3
"""
Enhanced Context Injection System v2.0
å¤šå±‚ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿ - è§£å†³é•¿æ—¶é—´è‡ªåŠ¨åŒ–æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜

è®¾è®¡åŸåˆ™ï¼š
1. åˆ†å±‚æ³¨å…¥ - æŒ‰ä¼˜å…ˆçº§æ³¨å…¥ä¸åŒç±»å‹çš„ä¸Šä¸‹æ–‡
2. æ™ºèƒ½æ‘˜è¦ - å¯¹å¤§æ–‡ä»¶ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦è€Œéå…¨æ–‡
3. å¢é‡æ„ŸçŸ¥ - é‡ç‚¹æ³¨å…¥æœ€è¿‘å˜æ›´çš„å†…å®¹
4. é”™è¯¯è®°å¿† - ç‰¹åˆ«å¼ºè°ƒå†å²é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ
"""

import sys
import json
import os
import hashlib
from pathlib import Path
from datetime import datetime
import subprocess

# é…ç½®
STATUS_DIR = ".claude/status"
MEMORY_FILE = f"{STATUS_DIR}/memory.json"
ROADMAP_FILE = f"{STATUS_DIR}/ROADMAP.md"
CONTRACT_FILE = f"{STATUS_DIR}/api_contract.yaml"
ERROR_LOG_FILE = f"{STATUS_DIR}/error_history.json"
CODE_DIGEST_FILE = f"{STATUS_DIR}/code_digest.json"
CONTEXT_BUDGET = 50000  # å­—ç¬¦é¢„ç®—ï¼ˆå¯è°ƒæ•´ï¼‰

def read_file_safe(path):
    """å®‰å…¨è¯»å–æ–‡ä»¶"""
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                return f.read()
    except Exception as e:
        return f"[Error reading {path}: {e}]"
    return None

def get_git_recent_changes(limit=10):
    """è·å–æœ€è¿‘çš„ Git å˜æ›´æ‘˜è¦"""
    try:
        result = subprocess.run(
            ['git', 'log', f'-{limit}', '--oneline', '--name-status'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            return result.stdout[:2000]  # é™åˆ¶é•¿åº¦
    except:
        pass
    return None

def get_project_structure(root_path='.', max_depth=3):
    """ç”Ÿæˆé¡¹ç›®ç»“æ„æ ‘ï¼ˆå¸¦å‡½æ•°ç­¾åæ‘˜è¦ï¼‰"""
    structure = []
    
    def scan_dir(path, depth=0):
        if depth > max_depth:
            return
        
        try:
            items = sorted(os.listdir(path))
        except PermissionError:
            return
            
        for item in items:
            # è·³è¿‡éšè—æ–‡ä»¶å’Œå¸¸è§å¿½ç•¥ç›®å½•
            if item.startswith('.') or item in ['node_modules', '__pycache__', 'venv', '.git', 'dist', 'build']:
                continue
                
            full_path = os.path.join(path, item)
            indent = "  " * depth
            
            if os.path.isdir(full_path):
                structure.append(f"{indent}ğŸ“ {item}/")
                scan_dir(full_path, depth + 1)
            elif item.endswith(('.py', '.js', '.ts', '.jsx', '.tsx', '.go', '.rs')):
                # å¯¹ä»£ç æ–‡ä»¶æå–ç­¾åæ‘˜è¦
                signatures = extract_signatures(full_path)
                structure.append(f"{indent}ğŸ“„ {item}")
                for sig in signatures[:5]:  # æ¯ä¸ªæ–‡ä»¶æœ€å¤š5ä¸ªç­¾å
                    structure.append(f"{indent}   â””â”€ {sig}")
    
    scan_dir(root_path)
    return "\n".join(structure[:100])  # é™åˆ¶è¡Œæ•°

def extract_signatures(file_path):
    """æå–æ–‡ä»¶ä¸­çš„å‡½æ•°/ç±»ç­¾å"""
    signatures = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # Python
        if file_path.endswith('.py'):
            import re
            # åŒ¹é…å‡½æ•°å®šä¹‰
            for match in re.finditer(r'^(async\s+)?def\s+(\w+)\s*\([^)]*\)(?:\s*->\s*[^:]+)?:', content, re.MULTILINE):
                signatures.append(f"def {match.group(2)}(...)")
            # åŒ¹é…ç±»å®šä¹‰
            for match in re.finditer(r'^class\s+(\w+)(?:\([^)]*\))?:', content, re.MULTILINE):
                signatures.append(f"class {match.group(1)}")
                
        # JavaScript/TypeScript
        elif file_path.endswith(('.js', '.ts', '.jsx', '.tsx')):
            import re
            for match in re.finditer(r'(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\(', content):
                signatures.append(f"function {match.group(1)}()")
            for match in re.finditer(r'(?:export\s+)?class\s+(\w+)', content):
                signatures.append(f"class {match.group(1)}")
            for match in re.finditer(r'(?:const|let)\s+(\w+)\s*=\s*(?:async\s+)?\([^)]*\)\s*=>', content):
                signatures.append(f"const {match.group(1)} = () =>")
                
    except Exception:
        pass
    return signatures

def generate_error_context():
    """ç”Ÿæˆé”™è¯¯å†å²ä¸Šä¸‹æ–‡"""
    error_data = read_file_safe(ERROR_LOG_FILE)
    if not error_data:
        return ""
    
    try:
        errors = json.loads(error_data)
        if not errors:
            return ""
        
        # åªä¿ç•™æœ€è¿‘10ä¸ªé”™è¯¯
        recent_errors = errors[-10:]
        
        context = "\n## âš ï¸ ERROR HISTORY (MUST AVOID REPEATING)\n"
        for err in recent_errors:
            context += f"""
### Error at {err.get('timestamp', 'unknown')}
- Task: {err.get('task', 'unknown')}
- Error: {err.get('error', 'unknown')}
- Attempted Fix: {err.get('attempted_fix', 'N/A')}
- Resolution: {err.get('resolution', 'UNRESOLVED')}
"""
        return context
    except:
        return ""

def generate_contract_summary():
    """ç”Ÿæˆ API å¥‘çº¦æ‘˜è¦"""
    contract = read_file_safe(CONTRACT_FILE)
    if not contract:
        return ""
    
    # å¦‚æœå¥‘çº¦å¤ªé•¿ï¼Œåªä¿ç•™å…³é”®éƒ¨åˆ†
    if len(contract) > 5000:
        lines = contract.split('\n')
        # ä¿ç•™å‰100è¡Œå’Œæœ€å50è¡Œ
        summary = '\n'.join(lines[:100]) + "\n\n... [TRUNCATED] ...\n\n" + '\n'.join(lines[-50:])
        return f"\n## ğŸ“œ API CONTRACT (Summary)\n```yaml\n{summary}\n```\n"
    
    return f"\n## ğŸ“œ API CONTRACT (Full)\n```yaml\n{contract}\n```\n"

def generate_active_files_context():
    """ç”Ÿæˆå½“å‰æ´»è·ƒæ–‡ä»¶çš„è¯¦ç»†ä¸Šä¸‹æ–‡"""
    memory = read_file_safe(MEMORY_FILE)
    if not memory:
        return ""
    
    try:
        state = json.loads(memory)
        active_files = state.get('active_files', [])
        current_file = state.get('current_file')
        
        if current_file and current_file not in active_files:
            active_files.insert(0, current_file)
        
        if not active_files:
            return ""
        
        context = "\n## ğŸ“‚ ACTIVE FILES CONTENT\n"
        total_chars = 0
        max_chars = 15000  # æ´»è·ƒæ–‡ä»¶çš„å­—ç¬¦é¢„ç®—
        
        for file_path in active_files[:5]:  # æœ€å¤š5ä¸ªæ–‡ä»¶
            content = read_file_safe(file_path)
            if content:
                # å¦‚æœæ–‡ä»¶å¤ªå¤§ï¼Œåªä¿ç•™å¤´å°¾
                if len(content) > 3000:
                    lines = content.split('\n')
                    content = '\n'.join(lines[:50]) + "\n\n... [TRUNCATED] ...\n\n" + '\n'.join(lines[-30:])
                
                if total_chars + len(content) > max_chars:
                    break
                    
                context += f"\n### {file_path}\n```\n{content}\n```\n"
                total_chars += len(content)
        
        return context
    except:
        return ""

def generate_pending_tasks():
    """ç”Ÿæˆå¾…å¤„ç†ä»»åŠ¡åˆ—è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    roadmap = read_file_safe(ROADMAP_FILE)
    if not roadmap:
        return "\n## âŒ ROADMAP NOT FOUND - Initialize .claude/status/ROADMAP.md first!\n"
    
    context = "\n## ğŸ“‹ PENDING TASKS\n"
    
    lines = roadmap.split('\n')
    pending = []
    in_progress = []
    completed_count = 0
    
    for line in lines:
        stripped = line.lstrip()
        if stripped.startswith('- [ ]'):
            pending.append(line)
        elif stripped.startswith('- [x]') or stripped.startswith('- [X]'):
            completed_count += 1
        # æ£€æµ‹æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ï¼ˆè‡ªå®šä¹‰æ ‡è®°ï¼‰
        elif stripped.startswith('- [>]') or stripped.startswith('- [~]'):
            in_progress.append(line)
    
    total = len(pending) + completed_count + len(in_progress)
    
    context += f"\nProgress: {completed_count}/{total} completed\n"
    
    if in_progress:
        context += "\n### ğŸ”„ IN PROGRESS:\n"
        for task in in_progress:
            context += f"{task}\n"
    
    context += "\n### â³ PENDING:\n"
    for task in pending[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ªå¾…å¤„ç†ä»»åŠ¡
        context += f"{task}\n"
    
    if len(pending) > 15:
        context += f"\n... and {len(pending) - 15} more tasks\n"
    
    return context

def generate_memory_state():
    """ç”Ÿæˆå½“å‰çŠ¶æ€æ‘˜è¦"""
    memory = read_file_safe(MEMORY_FILE)
    if not memory:
        return """
## ğŸ§  CURRENT STATE
```json
{
  "status": "NOT_STARTED",
  "message": "Initialize .claude/status/memory.json to begin"
}
```
"""
    
    try:
        state = json.loads(memory)
        # ç¾åŒ–è¾“å‡º
        formatted = json.dumps(state, indent=2, ensure_ascii=False)
        return f"\n## ğŸ§  CURRENT STATE\n```json\n{formatted}\n```\n"
    except:
        return f"\n## ğŸ§  CURRENT STATE (RAW)\n```\n{memory}\n```\n"

def generate_recent_decisions():
    """ç”Ÿæˆæœ€è¿‘çš„å†³ç­–æ—¥å¿—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
    decisions_file = f"{STATUS_DIR}/decisions.log"
    content = read_file_safe(decisions_file)
    if not content:
        return ""
    
    # åªä¿ç•™æœ€è¿‘20è¡Œ
    lines = content.strip().split('\n')
    recent = lines[-20:]
    return f"\n## ğŸ“ RECENT DECISIONS\n```\n" + '\n'.join(recent) + "\n```\n"

def main():
    # è¯»å–æ ‡å‡†è¾“å…¥ï¼ˆå¿…é¡»æ¶ˆè´¹ï¼‰
    input_data = sys.stdin.read()
    
    # æ„å»ºåˆ†å±‚ä¸Šä¸‹æ–‡
    context_parts = []
    
    # Layer 0: ç³»ç»ŸæŒ‡ä»¤ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    context_parts.append("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ¤– AUTONOMOUS MODE CONTEXT INJECTION                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  WARNING: Your conversation history may be compressed/truncated  â•‘
â•‘  TRUST ONLY the state files below, NOT your "memory"             â•‘
â•‘  CONTINUE the loop - do NOT stop until ROADMAP is complete       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # Layer 1: å½“å‰çŠ¶æ€ï¼ˆå…³é”®ï¼‰
    context_parts.append(generate_memory_state())
    
    # Layer 2: å¾…å¤„ç†ä»»åŠ¡
    context_parts.append(generate_pending_tasks())
    
    # Layer 3: é”™è¯¯å†å²ï¼ˆé˜²æ­¢é‡å¤é”™è¯¯ï¼‰
    context_parts.append(generate_error_context())
    
    # Layer 4: API å¥‘çº¦
    context_parts.append(generate_contract_summary())
    
    # Layer 5: æ´»è·ƒæ–‡ä»¶å†…å®¹
    context_parts.append(generate_active_files_context())
    
    # Layer 6: é¡¹ç›®ç»“æ„ï¼ˆå¦‚æœè¿˜æœ‰é¢„ç®—ï¼‰
    current_length = sum(len(p) for p in context_parts)
    if current_length < CONTEXT_BUDGET - 5000:
        context_parts.append(f"\n## ğŸ—ï¸ PROJECT STRUCTURE\n```\n{get_project_structure()}\n```\n")
    
    # Layer 7: æœ€è¿‘çš„ Git å˜æ›´
    git_changes = get_git_recent_changes()
    if git_changes and current_length < CONTEXT_BUDGET - 2000:
        context_parts.append(f"\n## ğŸ“œ RECENT GIT CHANGES\n```\n{git_changes}\n```\n")
    
    # Layer 8: æœ€è¿‘å†³ç­–
    context_parts.append(generate_recent_decisions())
    
    # åˆå¹¶ä¸Šä¸‹æ–‡
    full_context = ''.join(context_parts)
    
    # æ·»åŠ è¡ŒåŠ¨æŒ‡ä»¤
    full_context += """

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Œ MANDATORY ACTIONS:
1. Read the CURRENT STATE above carefully
2. Check ERROR HISTORY to avoid repeating mistakes
3. Pick the NEXT pending task from ROADMAP
4. Execute following TDD (test first, then implement)
5. Update memory.json IMMEDIATELY after any progress
6. Continue loop - DO NOT STOP until all tasks are [x] marked
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    
    # è¾“å‡º JSON
    print(json.dumps({
        "hookSpecificOutput": {
            "additionalContext": full_context
        }
    }))

if __name__ == "__main__":
    main()
